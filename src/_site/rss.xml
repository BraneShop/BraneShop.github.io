<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"
    xmlns:dc="http://purl.org/dc/elements/1.1/">
    <channel>
        <title>Braneshop | braneshop.com.au</title>
        <link>https://braneshop.com.au</link>
        <description><![CDATA[The blog of the Braneshop team.]]></description>
        <atom:link href="https://braneshop.com.au/rss.xml" rel="self"
                   type="application/rss+xml" />
        <lastBuildDate>Wed, 24 Jul 2019 00:00:00 UT</lastBuildDate>
        <item>
    <title>Scholarships for August Technical Deep Learning Workshop Close on Sunday!</title>
    <link>https://braneshop.com.au/posts/Aug-2019-Scholarships-Close-On-Sunday.html</link>
    <description><![CDATA[<p>Ruth and I are very pleased to be offering scholarships for our workshop coming up on the 8th of August. We’ve already accept first-round scholarships (6 people), and so there are some remaining places.</p>
<p>We’re encouraging applications from anyone that has typically faced barriers in their career/learning in the tech industry. One of our big aims at Braneshop is to increase the representation in the AI industry, and this is one way we’re working towards that goal.</p>
<p>You can find the application form here: <a href="https://noonvandersilk.typeform.com/to/Tnfm4a">Scholarship for the 6 Week Technical Deep Learning Workshop</a>, and of course more details about the workshop itself here: <a href="/6-week-workshop-on-deep-learning.html">6 Week Workshop</a>.</p>
<p>We’ve also got a scholarship for the <a href="/ai-for-leadership.html">AI For Leadership Workshop</a>, coming up in September. This is an important one for us as well, as, in order to see change broadly through-out the industry, we will need change in leadership positions.</p>
<p>Here at the Braneshop we’re creating a welcoming and supportive community for everyone to be involved in AI. We hope you join us!</p>
]]></description>
    <pubDate>Wed, 24 Jul 2019 00:00:00 UT</pubDate>
    <guid>https://braneshop.com.au/posts/Aug-2019-Scholarships-Close-On-Sunday.html</guid>
    <dc:creator>Braneshop Team</dc:creator>
</item>
<item>
    <title>Deep learning showreel now online!</title>
    <link>https://braneshop.com.au/posts/Showreel-Online.html</link>
    <description><![CDATA[<p>We love staying up to date with the latest deep learning research. I typically catch up daily, via the <a href="https://scirate.com">SciRate</a> website (check if out if you haven’t already!)</p>
<p>Every now and then, a paper really stands out as either cool, interesting, innovative, or useful. When something really appealed to me, I’d typically post it in various places, such as LinkedIn, or slack, or twitter, or just file it away in my head, waiting for the perfect moment to pop up again.</p>
<p>We also typically include these as part of the workshops, to get people a bit excited about the field.</p>
<p>Well, now I’ve decided to put that list online: <a href="/showreel.html">Deep learning showreel!</a></p>
]]></description>
    <pubDate>Thu, 11 Jul 2019 00:00:00 UT</pubDate>
    <guid>https://braneshop.com.au/posts/Showreel-Online.html</guid>
    <dc:creator>Braneshop Team</dc:creator>
</item>
<item>
    <title>State of the art attention models in PyText - Part 1</title>
    <link>https://braneshop.com.au/posts/State-of-the-art-attention-models-in-PyText-Part-1.html</link>
    <description><![CDATA[<p>I wanted to take some time to discuss a library that seems to have flown under the radar a little bit. It’s called <a href="https://github.com/facebookresearch/pytext">PyText</a>, and we’re going to explore how you can use it to run state of the art attention models!</p>
<p>Here’s our plan:</p>
<ol style="list-style-type: decimal">
<li>Set a dataset,</li>
<li>See how we prepare the data for training in PyText,</li>
<li>Get PyText,</li>
<li>Train it,</li>
<li>Visualise it,</li>
<li>Consider extensions,</li>
</ol>
<p>Finally, we’ll jump in to a fork of PyText where I’ve added a few features that help out during training.</p>
<p>If you want to follow along, all the code for this post is available <a href="https://github.com/Braneshop/pytext">here</a>.</p>
]]></description>
    <pubDate>Wed, 03 Jul 2019 00:00:00 UT</pubDate>
    <guid>https://braneshop.com.au/posts/State-of-the-art-attention-models-in-PyText-Part-1.html</guid>
    <dc:creator>Braneshop Team</dc:creator>
</item>
<item>
    <title>Venue for the first workshop - BlueRock!</title>
    <link>https://braneshop.com.au/posts/2019-06-28-First-workshop-at-Blue-Rock.html</link>
    <description><![CDATA[<p>We’re very grateful to the very nice people at <a
href="https://thebluerock.com.au/" rel="noopener">BlueRock</a> (be sure to check out their website!) who have agreed to be our venue hosts for the upcoming <a
href="/6-week-workshop-on-deep-learning.html">6 week technical deep learning workshop</a>, kicking off on the 8th of August!</p>
]]></description>
    <pubDate>Fri, 28 Jun 2019 00:00:00 UT</pubDate>
    <guid>https://braneshop.com.au/posts/2019-06-28-First-workshop-at-Blue-Rock.html</guid>
    <dc:creator>Braneshop Team</dc:creator>
</item>
<item>
    <title>Deep learning quick start</title>
    <link>https://braneshop.com.au/posts/2019-06-21-Deep-learning-quick-start.html</link>
    <description><![CDATA[<p>It’s been in vogue for some time now to have a little “quick-start” install on your website. Notable examples are:</p>
<ul class="normal">
<li>
The <a href="https://spacy.io/usage" rel="noopener">spaCy</a> website,
</li>
<li>
<a href="https://pytorch.org/" rel="noopener">PyTorch</a>.
</li>
</ul>
<p>My friend Hayden suggested that it might be nice to have a slightly higher-level one, so I made it: <a href="/quickstart.html">Braneshop deep learning quick start</a>, and you can find a link to it at the bottom of the page.</p>
<p>The main thing I wanted to get across, for whatever it’s worth, is that one of your best options is <a href="https://colab.research.google.com/">Google Colaboratory</a>. The other thing I did was to just collect together the information from the TensorFlow and the PyTorch installation pages.</p>
]]></description>
    <pubDate>Fri, 21 Jun 2019 00:00:00 UT</pubDate>
    <guid>https://braneshop.com.au/posts/2019-06-21-Deep-learning-quick-start.html</guid>
    <dc:creator>Braneshop Team</dc:creator>
</item>
<item>
    <title>Ruth joins Braneshop, and new workshop launch!</title>
    <link>https://braneshop.com.au/posts/2019-06-09-Ruth-joins-Braneshop-and-Workshop-Launch.html</link>
    <description><![CDATA[<p>Hello friends!</p>
<p>This is your first Braneshop blog post from me, and I’m very excited to be writing it to tell you about our first <a href="/6-week-workshop-on-deep-learning.html">6 Week Technical Deep Learning Workshop</a> scheduled to start on the 8th of August, which is <a href="https://events.humanitix.com.au/braneshop-6-week-technical-deep-learning-workshop">on sale now!</a></p>
<p>(Not to mention our first <a href="/ai-for-leadership.html">AI for Leadership</a> workshop which is also on sale now, and our <a href="/deep-learning-workshop.html">Intensive Technical Deep Learning Workshop</a> which we can bring to your organisation — <a href="https://noonvandersilk.typeform.com/to/DYKvWN">get in touch!</a>)</p>
<p>I recently joined my friend Noon at Braneshop as an instructor, here’s why:</p>
]]></description>
    <pubDate>Sun, 09 Jun 2019 00:00:00 UT</pubDate>
    <guid>https://braneshop.com.au/posts/2019-06-09-Ruth-joins-Braneshop-and-Workshop-Launch.html</guid>
    <dc:creator>Braneshop Team</dc:creator>
</item>
<item>
    <title>Deep learning in the browser!</title>
    <link>https://braneshop.com.au/posts/2019-04-10-Deep-learning-in-the-browser-at-the-web-meetup.html</link>
    <description><![CDATA[<p>Last night I gave a talk at <a href="https://www.meetup.com/the-web/events/260211393/">The Web Meetup</a> on deep learning in the browser. It was mostly about how to deploy models built TensorFlow to the browser, by way of TensorFlow.js, but we did manage to try a model on the <a href="https://colab.research.google.com/">Google Colaboratory</a>, and deploy it to the browser all in the space of about 5 minutes!</p>
<p>We also discussed a few of the items that I brought up in my recent post about <a href="/posts/2019-02-08-TensorFlowJS-How-to-easily-deploy-deep-learning-models.html">deploying models via TensorFlow.js</a>.</p>
<center>
<img src="/images/blog/wmu-1.jpg" /> <br /> Deep learning in the browser! - Presentation at the April Web Meetup.
</center>
<p>Here are the links to the presentation and the code:</p>
<ul class="normal">
<li>
Presentation - <a href="https://docs.google.com/presentation/d/1_px6paltT1ZHZPKKTK_o-8KWKppremKcwe-5GY94kos/edit">Deep learning in the browser!</a>
</li>
<li>
Online Demo - <a href="https://silky.github.io/tfjs-fashion-mnist-classifier/index.html">tfjs fashion mnist classifier</a>
<li>
Code - <a href="https://github.com/silky/tfjs-fashion-mnist-classifier" class="uri">https://github.com/silky/tfjs-fashion-mnist-classifier</a>
</li>
</ul>
<p>Some of the discussion points from the audience were:</p>
]]></description>
    <pubDate>Wed, 10 Apr 2019 00:00:00 UT</pubDate>
    <guid>https://braneshop.com.au/posts/2019-04-10-Deep-learning-in-the-browser-at-the-web-meetup.html</guid>
    <dc:creator>Braneshop Team</dc:creator>
</item>
<item>
    <title>Australian Human Rights Commission AI - Submission</title>
    <link>https://braneshop.com.au/posts/2019-03-14-HRC-AI-Submission.html</link>
    <description><![CDATA[<p>At Braneshop we’re keen to see AI develop positively in our community. The rules and regulation around AI will play a key role in ensuring that the AI that is ultimately built and used ends up creating good community outcomes.</p>
<p>The Australian Human Rights Commission recently put out a <a href="https://tech.humanrights.gov.au/consultation">call for consultation on AI - Governance and Leadership</a>. The deadline for a submission is the 18th of March at 5pm (so there’s still time if you’re quick!)</p>
<p>Working with Martin and Sam at <a href="https://www.northraine.com/">Northraine</a> and other interested parties, we prepared a joint submission, which you can read here: <a href="/files/HRC_Submission.pdf">Our HRC Submission</a>.</p>
]]></description>
    <pubDate>Thu, 14 Mar 2019 00:00:00 UT</pubDate>
    <guid>https://braneshop.com.au/posts/2019-03-14-HRC-AI-Submission.html</guid>
    <dc:creator>Braneshop Team</dc:creator>
</item>
<item>
    <title>Mindful Neural Networks</title>
    <link>https://braneshop.com.au/posts/2019-03-06-Mindful-Neural-Networks.html</link>
    <description><![CDATA[<p>Last night at the <a href="https://www.meetup.com/Melbourne-Creative-AI-Meetup/">Creative AI Meetup</a> we had an awesome conversation around the idea of “Mindful” neural networks.</p>
<center>
<img width="600" src="/images/blog/thich-nhat-tanh.png" /> <br /> <i>Thich Nhat Tanh</i>
</center>
<p>We were hosted by our friends at <a href="https://sheda.ltd">Sheda</a> over the <a href="https://neighbourhood.work">Neighbourhood.work</a> in Fitzroy, and we had a really nice group of people with varied and interesting backgrounds show up:</p>
<center>
<a href="/images/blog/creative-ai-march-2019.jpg"><img width="600" src="/images/blog/creative-ai-march-2019.jpg" /></a> <br /> <i>The Mindful Neural Network Group. Photo courtesy of Eike!</i>
</center>
<p>We did the usual Creative-AI opening where we review a bunch of recent innovations in the field in the last few weeks. You can find the projects we discussed by looking over the slides here: <a href="https://docs.google.com/presentation/d/167A6XXp9NIOb0tPTls51PveyMgKjGEEpKaeospVr54g/edit">Creative AI Meetup - March 2019</a>.</p>
]]></description>
    <pubDate>Wed, 06 Mar 2019 00:00:00 UT</pubDate>
    <guid>https://braneshop.com.au/posts/2019-03-06-Mindful-Neural-Networks.html</guid>
    <dc:creator>Braneshop Team</dc:creator>
</item>
<item>
    <title>The Canary Set for Machine Learning Applications</title>
    <link>https://braneshop.com.au/posts/2019-03-01-The-Canary-Set.html</link>
    <description><![CDATA[<p>Earlier this week I was chatting to some people and we came up with a good idea. It’s what I refer to now as the “Canary Set”.</p>
<p>We’re probably all familiar with the standard “canary in the cage” idea:</p>
<center>
<p>
The standard canary in a cage.
</p>
<img src="/images/blog/canary-cage.png" alt="The standard canary in a cage." />
</center>
<p>It’s an item that can be carried with you into your hazardous job, and when it dies, it’s suggestive that the place your working in is unsafe. Poor canary.</p>
<p>I’d like to propose that this can be a useful idea in machine learning, where instead of a canary, we carry around an “interesting set” of data:</p>
<center>
<p>
A Canary Set of interesting data points.
</p>
<img src="/images/blog/canary-cage-data.png" alt="A Canary Set of data" />
</center>
<p>This would be called the “Canary Set” of data, and every time a new deployment of your ML model comes out, you run the mdoel across this dataset to see how it performs.</p>
<center>
<p>
Going in …
</p>
<br/> <img src="/images/blog/canary-cage-ai.png" alt="The canary set going through the next version of the AI" /> <br /> <br />
<p>
Coming out with a report …
</p>
<br/> <img src="/images/blog/canary-cage-ai-out.png" alt="The canary set coming out with a report!" />
</center>
<p>Let’s go into a few details of why we might want this, how it differs from the “test” or “validation” set during the training/evaluation phase of machine learning algorithms, and what benefits we might get from it.</p>
]]></description>
    <pubDate>Fri, 01 Mar 2019 00:00:00 UT</pubDate>
    <guid>https://braneshop.com.au/posts/2019-03-01-The-Canary-Set.html</guid>
    <dc:creator>Braneshop Team</dc:creator>
</item>

    </channel>
</rss>
