<?xml version="1.0" encoding="UTF-8" ?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
  <meta name="google-site-verification" content="cKie6SUiby1JmI2F8RMscJRBTa28kTM6XNHS5l1GXxc" />
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-131177872-1"></script>
  <script>
    var host = window.location.hostname;
    if ( host != "localhost") {
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-131177872-1');
    }
  </script>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
  <title>Braneshop - Deep learning showreel!</title>
  <meta name="geo.region" content="AU-VIC" />
  <meta name="geo.placename" content="Melbourne" />
  <link rel="stylesheet" type="text/css" href="./css/default.css" />
  <link rel="stylesheet" type="text/css" href="./css/syntax.css" />
  <link href="https://fonts.googleapis.com/css?family=PT+Mono|Lato|DM+Serif+Text" rel="stylesheet">
  <script type="text/javascript" src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  <!-- Facebook Pixel Code -->
  <script>
    !function(f,b,e,v,n,t,s)
    {if(f.fbq)return;n=f.fbq=function(){n.callMethod?
    n.callMethod.apply(n,arguments):n.queue.push(arguments)};
    if(!f._fbq)f._fbq=n;n.push=n;n.loaded=!0;n.version='2.0';
    n.queue=[];t=b.createElement(e);t.async=!0;
    t.src=v;s=b.getElementsByTagName(e)[0];
    s.parentNode.insertBefore(t,s)}(window, document,'script',
    'https://connect.facebook.net/en_US/fbevents.js');
    fbq('init', '382844492347906');
    fbq('track', 'PageView');
  </script>
  <noscript><img height="1" width="1" style="display:none" src="https://www.facebook.com/tr?id=382844492347906&ev=PageView&noscript=1" /></noscript>
  <!-- End Facebook Pixel Code -->
</head>
<body>
  <div id="braneshop-fixed" onclick="document.location = '/';"></div>


  <!-- Header -->
  <div id="header">
    <div class="top">
      <div class="logos">
        <h1><a href="./"><img id="header-logo" class="compressed" src="./images/braneshop-blue.png" title="Braneshop" alt="Braneshop" /></a></h1>
      </div>

      
        <div class="m">
          <ul class="menu">
            <li><a href="./" title="Home">Home</a>|</li>
            <li><a href="./team.html" title="Team">Team</a>|</li>
            <li><a href="./community.html" title="Community">Community</a>|</li>
            <li><a href="./blog.html" title="Blog">Blog</a>|</li>
            <li><a href="./faq.html" title="FAQs">FAQs</a>|</li>
            <li><a href="./showreel.html" title="Showreel">Showreel</a>|</li>
            <li><a href="./contact.html" title="Contact">Contact</a></li>
          </ul>
          <ul class="menu smaller">
            <li><a href="./6-week-workshop-on-deep-learning.html" title="6 Week Workshop">6 Week Workshop</a>
              <span class="important">(Starts 8-Aug)</span> |
              </li>
            <li><a href="./ai-for-leadership.html" title="AI For Leadership">AI For Leadership</a>
              <span class="important">(On 23-Sep)</span> |
              </li>
            <li><a href="./deep-learning-workshop.html" title="Intensive Technical Deep Learning Workshop">Intensive Workshop</a></li>
          </ul>
        </div>
      
    </div>
    <small>Expand your knowledge manifold!</small>
  </div>


  <!-- Content -->
  <div id="content">
    <div class="section" id="showreel">
  <a name="showreel"></a>
  <h3> <span>üé• Deep learning showreel! </span> </h3>
  <div id="show-reel">
    <p>
    We closely follow research in deep learning and AI. Here are a collection
    of cool, interesting, and fun applications that we've seen, with a brief
    explanation and a link to the original paper. All figures are taken
    directly from the paper or the associated website.
    </p>

    <p>Check back for regular updates, or sign up to the newsletter (below) to
    receive the latest cool stuff, monthly!</p>

    <ul class="blog-list normal">
  
    
    <li> 
        
          <div class="showreel-card">
        
        <h5> <a href="https://arxiv.org/pdf/1907.04135.pdf" rel="noopener">What-If ... We could interactively understand ML Models?</a> &mdash; July  9, 2019 </h5>

        
          <span class="tags">Tags: <a href="./showreel-tags/visualisation.html">visualisation</a></span>
        

        <div class="content">
          
          <center><a href="./images/showreel/What-If ... We could interactively understand ML Models.jpg"><img src="./images/showreel/What-If ... We could interactively understand ML Models.jpg" width="800" /></a></center>
          

          <p>This is some software that Google put out a few years ago under a different name (it was called ‚Äúfacets‚Äù). This specific tool I‚Äôm not so convinced on, but it‚Äôs a very good attempt to tackle a very important idea ‚Äî how bias and decision-making can be understood interactively.</p>

        </div>
      </li>
      
  
    
    
  
    
    <li> 
        
          <div class="showreel-card">
        
        <h5> <a href="https://arxiv.org/pdf/1907.03537.pdf" rel="noopener">Linking Art through Human Poses</a> &mdash; July  8, 2019 </h5>

        
          <span class="tags">Tags: <a href="./showreel-tags/art.html">art</a>, <a href="./showreel-tags/pose.html">pose</a>, <a href="./showreel-tags/computer-vision.html">computer-vision</a></span>
        

        <div class="content">
          
            <center><a href="./images/showreel/Linking Art through Human Poses.jpg"><img src="./images/showreel/Linking Art through Human Poses.jpg" /></a></center>
          

          <p>This one is cool for the kind of neat technique it demonstrates. They use a pose network (something that just looks at an image of a person, say, and estimates what their skeleton looks like; i.e.¬†it tries to guess some straight lines that connect their arms and legs and such) to connect different artworks. It‚Äôs a neat application of what is becoming a standard technique.</p>

        </div>
      </li>
      
  
    
    <li> 
        
          <div class="showreel-card">
        
        <h5> <a href="https://arxiv.org/pdf/1907.03381.pdf" rel="noopener">Estimating travel time without roads</a> &mdash; July  8, 2019 </h5>

        
          <span class="tags">Tags: <a href="./showreel-tags/computer-vision.html">computer-vision</a></span>
        

        <div class="content">
          
            <center><a href="./images/showreel/Estimating travel time without roads.jpg"><img src="./images/showreel/Estimating travel time without roads.jpg" /></a></center>
          

          <p>Again, a neat idea applied well. In this paper they suppose that, in fact, we don‚Äôt need detailed road networks to do reasonably well at estimating travel time. We just need to get a vague feeling for the kinds of areas we‚Äôll be travelling though (i.e.¬†highway, commercial, residential, country, park, urban, etc). They make these ideas precise and get some great results!</p>

        </div>
      </li>
      
  
    
    <li> 
        
          <div class="showreel-card">
        
        <h5> <a href="https://arxiv.org/pdf/1907.03520.pdf" rel="noopener">Action Recognition from Poses</a> &mdash; July  8, 2019 </h5>

        
          <span class="tags">Tags: <a href="./showreel-tags/pose.html">pose</a></span>
        

        <div class="content">
          
            <center><a href="./images/showreel/Action Recognition from Poses.jpg"><img src="./images/showreel/Action Recognition from Poses.jpg" /></a></center>
          

          <p>A pretty standard, but useful, technique that uses a kind of multi-stage process to: 1) compute the pose, 2) then from the a series of these poses, ver time, work out what ‚Äúaction‚Äù people are performing. Specifically here they focus on people going past train ticket machines in various ways, but the application is general.</p>

        </div>
      </li>
      
  
    
    
  
    
    
  
    
    <li> 
        
          <div class="showreel-card">
        
        <h5> <a href="https://arxiv.org/pdf/1907.02040.pdf" rel="noopener">Albatrosses from Space</a> &mdash; July  3, 2019 </h5>

        
          <span class="tags">Tags: <a href="./showreel-tags/science.html">science</a></span>
        

        <div class="content">
          
            <center><a href="./images/showreel/Albatrosses from Space.jpg"><img src="./images/showreel/Albatrosses from Space.jpg" /></a></center>
          

          <p>A really nice scientific application of deep learning; and something that maybe any reasonable person would not assume is possible right now. We like this one because it‚Äôs the overlap of modern deep learning techniques to old (but important!) problems of tracking animal movements for conservation reasons.</p>

        </div>
      </li>
      
  
    
    <li> 
        
          <div class="showreel-card" style="width: 550px;">
        
        <h5> <a href="https://arxiv.org/pdf/1907.02014.pdf" rel="noopener">AI for Economic Uplift of Handicraft</a> &mdash; May 31, 2019 </h5>

        
          <span class="tags">Tags: <a href="./showreel-tags/art.html">art</a></span>
        

        <div class="content">
          
            <center><a href="./images/showreel/AI for Economic Uplift of Handicraft.jpg"><img src="./images/showreel/AI for Economic Uplift of Handicraft.jpg" /></a></center>
          

          <p>While this one isn‚Äôt strictly using deep learning, it does use some classical machine learning techniques. But the reason we consider it particularly cool, is because the authors actually took their system ‚Äúto the streets‚Äù, as it were, and verified that using the new design processes helped the artisans sell more items!</p>

        </div>
      </li>
      
  
    
    
  
    
    
  
    
    
  
    
    <li> 
        
          <div class="showreel-card">
        
        <h5> <a href="https://arxiv.org/pdf/1904.07595.pdf" rel="noopener">Detecting the Unexpected</a> &mdash; April 16, 2019 </h5>

        
          <span class="tags">Tags: <a href="./showreel-tags/computer-vision.html">computer-vision</a>, <a href="./showreel-tags/technical.html">technical</a></span>
        

        <div class="content">
          
            <center><a href="./images/showreel/Detecting the Unexpected.jpg"><img src="./images/showreel/Detecting the Unexpected.jpg" /></a></center>
          

          <p>This is a really neat and important idea. The application here is in self-driving cars, but the central idea is very general. The main point is, if we‚Äôve trained a network to detect certain classes of thing (‚Äúcar‚Äù, ‚Äúroad‚Äù, ‚Äúperson‚Äù, ‚Äútruck‚Äù) then, if it sees something completely unexpected, (‚Äúgoose‚Äù), what will it predict? Depending on how you set up the network, it will predict one of the known classes. This work is about quantifying how confident the network should feel about such prediction. Their idea is to ask the network to think about how well it can reconstrut the thing it thought it saw. If it finds it hard, then that indicates that the thing it saw is moderately unknown to it, and so it shouldn‚Äôt be confident. As we have more AI out in real life making decisions, quantifying uncertainty will become increasingly important.</p>

        </div>
      </li>
      
  
    
    
  
    
    <li> 
        
          <div class="showreel-card">
        
        <h5> <a href="https://arxiv.org/pdf/1904.05866.pdf" rel="noopener">Expressive 3D Body Capture from a Single Image</a> &mdash; April 11, 2019 </h5>

        
          <span class="tags">Tags: <a href="./showreel-tags/computer-vision.html">computer-vision</a>, <a href="./showreel-tags/pose.html">pose</a></span>
        

        <div class="content">
          
            <center><a href="./images/showreel/Expressive 3D Body Capture from a Single Image.jpg"><img src="./images/showreel/Expressive 3D Body Capture from a Single Image.jpg" /></a></center>
          

          <p>More and more we‚Äôre seeing deep learning tackle rich reconstruction problems from simple inputs. This is a classic of the genre. As humans, we can easily imagine the 3D structure of the person in the photo; and it turns out now deep learning can do the same, via the techniques in this paper. It‚Äôs very impressive work, and is applicable for those people wishing to capture this information without a complicated set up of a 3D body scanner. As usual, the typical applications will be in retail, but maybe also augmented-reality and other such fun things. As is the case with all these body-pose-related papers, they use an underlying pose network and build on top of it‚Äôs outputs. This is also a central and important topic in modern AI: building up rich and strong capabilities by combining different techniques.</p>

        </div>
      </li>
      
  
    
    <li> 
        
          <div class="showreel-card">
        
        <h5> <a href="https://arxiv.org/pdf/1904.03851.pdf" rel="noopener">Extreme Image Compression</a> &mdash; April  8, 2019 </h5>

        
          <span class="tags">Tags: <a href="./showreel-tags/technical.html">technical</a></span>
        

        <div class="content">
          
            <center><a href="./images/showreel/Extreme Image Compression.jpg"><img src="./images/showreel/Extreme Image Compression.jpg" /></a></center>
          

          <p>A natural thought would be that if we know a lot about the thing we‚Äôre trying to compress, we can do a better job. Standard compression algorithms are general-purpose, and as such, there is probably room to improve. This is the observation and work in this paper: They <em>learn</em> a compression function for a specific set of data, and they do really well! Probably not suitable for most of us, but you can be sure the big data storage providers will be working on these kinds of techniques into the future.</p>
<p>If we wanted to be trendy we could summarise this as ‚Äúbig data makes small data‚Äù.</p>

        </div>
      </li>
      
  
    
    <li> 
        
          <div class="showreel-card" style="width: 600px;">
        
        <h5> <a href="https://scirate.com/arxiv/1904.02579" rel="noopener">Can a Robot Become a Movie Director?</a> &mdash; April  5, 2019 </h5>

        
          <span class="tags">Tags: <a href="./showreel-tags/drones.html">drones</a>, <a href="./showreel-tags/computer-vision.html">computer-vision</a></span>
        

        <div class="content">
          
          <center><a href="./images/showreel/1904.02579.png"><img src="./images/showreel/1904.02579.png" width="500px" /></a></center>
          

          <p>The main point here is that if we‚Äôre interested in determining where to point a drone while filming some scene, it might be hard, because the director would need to be able to somehow see everything, while the drone is flying. This paper proposes that perhaps thee could be a method to have the drone know where to look.</p>

        </div>
      </li>
      
  
    
    <li> 
        
          <div class="showreel-card">
        
        <h5> <a href="https://arxiv.org/pdf/1904.03189.pdf" rel="noopener">Image2StyleGan - aka Ryan Obama aka Oprah Johansson</a> &mdash; April  5, 2019 </h5>

        
          <span class="tags">Tags: <a href="./showreel-tags/art.html">art</a>, <a href="./showreel-tags/computer-vision.html">computer-vision</a>, <a href="./showreel-tags/generative.html">generative</a>, <a href="./showreel-tags/technical.html">technical</a></span>
        

        <div class="content">
          
            <center><a href="./images/showreel/Image2StyleGan - aka Ryan Obama aka Oprah Johansson.jpg"><img src="./images/showreel/Image2StyleGan - aka Ryan Obama aka Oprah Johansson.jpg" /></a></center>
          

          <p>One of the most exciting areas of AI is the generative/creative opportunities. And in this area, something people are always fascinated by is the exploring the ‚Äúspace‚Äù of images; i.e here are all the photos of people, but what does a person who is ‚Äúhalfway between these two people‚Äù look like? This paper works on that problem, and produces some very cool looking people such as Ryan Obama, Oprah Johansson and Hugh de Niro. Notably, in this paper it seems like it doesn‚Äôt work so well for abstract/non-person style photos; but that‚Äôs probably due to the data, and not a general problem.</p>

        </div>
      </li>
      
  
    
    
  
    
    <li> 
        
          <div class="showreel-card">
        
        <h5> <a href="https://arxiv.org/pdf/1904.00276.pdf" rel="noopener">Detecting people using only WiFi</a> &mdash; March 30, 2019 </h5>

        
          <span class="tags">Tags: <a href="./showreel-tags/computer-vision.html">computer-vision</a>, <a href="./showreel-tags/pose.html">pose</a>, <a href="./showreel-tags/privacy.html">privacy</a></span>
        

        <div class="content">
          
            <center><a href="./images/showreel/Detecting people using only WiFi.jpg"><img src="./images/showreel/Detecting people using only WiFi.jpg" /></a></center>
          

          <p>This is an interesting one. WiFi is everywhere; and probably a reasonable person wouldn‚Äôt assume they could be tracked (down to estimates of where they are walking, and the overall pose of their body) if there isn‚Äôt a camera around. But it turns out that this data actually <em>can</em> be gathered in (an ideal) WiFi set up. That is, the pose of people was determined <em>without</em> a camera; using <em>only</em> WiFi signals. No doubt this field - sensing human activity through non-camera based sensors - will continue to grow.</p>

        </div>
      </li>
      
  
    
    
  
    
    <li> 
        
          <div class="showreel-card">
        
        <h5> <a href="https://arxiv.org/pdf/1903.04143.pdf" rel="noopener">Unconstrained Ear Recognition</a> &mdash; March 11, 2019 </h5>

        
          <span class="tags">Tags: <a href="./showreel-tags/computer-vision.html">computer-vision</a>, <a href="./showreel-tags/funny.html">funny</a></span>
        

        <div class="content">
          
            <center><a href="./images/showreel/Unconstrained Ear Recognition.jpg"><img src="./images/showreel/Unconstrained Ear Recognition.jpg" /></a></center>
          

          <p>Trust no-one. If you think covering your face is enough to stop <a href="https://en.wikipedia.org/wiki/Ferengi">people</a> from detecting who you are, you‚Äôre wrong. It turns out it‚Äôs possible to identify people from their ears. Why would anyone want to do this? Who knows. But it‚Äôs happening!</p>

        </div>
      </li>
      
  
    
    
  
    
    <li> 
        
          <div class="showreel-card">
        
        <h5> <a href="https://arxiv.org/pdf/1804.01622.pdf" rel="noopener">Image Generation from Scene Graphs</a> &mdash; April  4, 2018 </h5>

        
          <span class="tags">Tags: <a href="./showreel-tags/computer-vision.html">computer-vision</a>, <a href="./showreel-tags/generative.html">generative</a></span>
        

        <div class="content">
          
            <center><a href="./images/showreel/Image Generation from Scene Graphs.jpg"><img src="./images/showreel/Image Generation from Scene Graphs.jpg" /></a></center>
          

          <p>Work from the famous <a href="https://en.wikipedia.org/wiki/Fei-Fei_Li">Fei Fei Li</a>, this is a very neat idea. There‚Äôs been some famous networks (‚ÄúStackGAN‚Äù) that are able to generate pictures from text. But, they fail when you want to generate a complicated and unfamiliar scene. Humans, of course, can ‚Äúdis-entangle‚Äù different concepts when thinking of complicated scenes, such as ‚Äúa cat waiting to catch the train‚Äù. Even if we haven‚Äôt seen this exact thing before, we can easily imagine it, because we know how the things look, independently. The contribution in this work is the same idea, for neural networks, and they achieve awesome results! We can definitely expect significant improvements in this area, over the coming years.</p>

        </div>
      </li>
      
  
    
    <li> 
        
          <div class="showreel-card">
        
        <h5> <a href="https://arxiv.org/pdf/1711.08447.pdf" rel="noopener">Trying clothes on, virtually</a> &mdash; November 22, 2017 </h5>

        
          <span class="tags">Tags: <a href="./showreel-tags/fashion.html">fashion</a>, <a href="./showreel-tags/pose.html">pose</a></span>
        

        <div class="content">
          
            <center><a href="./images/showreel/Trying clothes on, virtually.jpg"><img src="./images/showreel/Trying clothes on, virtually.jpg" /></a></center>
          

          <p>This is a great example of attempting to apply AI in the real world. The problem here is the typical online-shopping problem: Here‚Äôs a thing that maybe I want to buy; but how would it look on me? This paper attempts to solve that problem by using pose information. It does a pretty good job for photos that are ‚Äúsimple‚Äù (i.e.¬†model on a white wall), and does a reasonable, but not great, job on what is referred to as photos ‚Äúin the wild‚Äù ‚Äî just photos from everyday life; inside or outside. Over the years we can expect to see this kind of technology hit on-line retailers.</p>

        </div>
      </li>
      
  
    
    <li> 
        
          <div class="showreel-card">
        
        <h5> <a href="https://arxiv.org/pdf/1711.05918.pdf" rel="noopener">Priming Neural Networks</a> &mdash; November 16, 2017 </h5>

        
          <span class="tags">Tags: <a href="./showreel-tags/computer-vision.html">computer-vision</a></span>
        

        <div class="content">
          
            <center><a href="./images/showreel/Priming Neural Networks.jpg"><img src="./images/showreel/Priming Neural Networks.jpg" /></a></center>
          

          <p>This is a fun one. First, try and find ‚Äúsomething‚Äù in the photo (it‚Äôs normal-sized; and you‚Äôll know it when you see it).</p>
<p>‚Ä¶</p>
<p>Did you find anything?</p>
<p>Now, try searching for: <span class="hidden">a cat</span> (highlight this section of text to see it). Can you find it now that I‚Äôve told you what to look for? Even if you can‚Äôt, it turns out that neural networks can. I think this is a really neat idea - priming a network to help it know what it‚Äôs trying to do.</p>

        </div>
      </li>
      
  
    
    <li> 
        
          <div class="showreel-card">
        
        <h5> <a href="https://scirate.com/arxiv/1701.04928" rel="noopener">Style Transfer in Come Swim</a> &mdash; January 19, 2017 </h5>

        
          <span class="tags">Tags: <a href="./showreel-tags/style-transfer.html">style-transfer</a>, <a href="./showreel-tags/art.html">art</a></span>
        

        <div class="content">
          
            <center><a href="./images/showreel/1701.04928.png"><img src="./images/showreel/1701.04928.png" /></a></center>
          

          <p>This is a landmark paper for a few reasons. First of all, it‚Äôs co-authored by a movie star; secondly it‚Äôs an application of the famous ‚Äústyle transfer‚Äù algorithm to a short film, and importantly that put a significant amount of work into making sure that the sylistic <em>quality</em> of the style transfer is high; which you don‚Äôt typically see. It‚Äôs a really interesting collaboration between the researchers and the film industry. I‚Äôm sure we‚Äôll see a lot more like this over the years!</p>

        </div>
      </li>
      
  
    
    <li> 
        
          <div class="showreel-card">
        
        <h5> <a href="https://arxiv.org/pdf/1512.04407.pdf" rel="noopener">Understanding and Predicting Visual Humour</a> &mdash; December 14, 2015 </h5>

        
          <span class="tags">Tags: <a href="./showreel-tags/funny.html">funny</a></span>
        

        <div class="content">
          
            <center><a href="./images/showreel/Understanding and Predicting Visual Humour.jpg"><img src="./images/showreel/Understanding and Predicting Visual Humour.jpg" /></a></center>
          

          <p>Easily Noons favourite paper of 2015. In life we face many problems. One of them is, given some non-funny situation, how can we make it funny? Naively one might think computers can‚Äôt begin to attemp to solve this problem. One would be wrong. Consider the top row of this image. Two people having dinner. Very unfunny. Two dogs having dinner at a dinner table? Hilarious. Likewise, cats in a park? Unfunny. A racoon riding a scooter in the same park? Brilliant.</p>
<p>This network was trained on data generated by humans who took specific scenes and adjusted them to make them funny.</p>
<p>We‚Äôre not totally sure where we‚Äôll see more applications of this work, but we love it.</p>

        </div>
      </li>
      
  
</ul>


  </div>
</div>

  </div>


  <!-- Footer -->
  <div id="footer">
    <div id="newsletter">

<!-- Mailchimp -->
      <a name="newsletter"></a>
      <h4>Newsletter!</h4>
<div id="mc_embed_signup">
<form action="https://braneshop.us19.list-manage.com/subscribe/post?u=e94e88a100517dd09f1720e55&amp;id=7957d3fc4c" method="post" id="mc-embedded-subscribe-form" name="mc-embedded-subscribe-form" class="validate" target="_blank" novalidate>
<p>‚úå Thanks for visiting! If you're interested, sign up to our newsletter to
receive monthly updates, and notifications of courses.
</p>
<div id="mc_embed_signup_scroll">
<div class="mc-field-group">
	<label for="mce-EMAIL">Email Address
</label>
	<input type="email" value name="EMAIL" class="required email" id="mce-EMAIL">
</div>
<div class="mc-field-group">
	<label for="mce-NAME">Name </label>
	<input type="text" value name="NAME" class id="mce-NAME">
</div>
	<div id="mce-responses" class="clear">
		<div class="response" id="mce-error-response" style="display:none"></div>
		<div class="response" id="mce-success-response" style="display:none"></div>
	</div>    <!-- real people should not fill this in and expect good things - do not remove this or risk form bot signups-->
    <div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_e94e88a100517dd09f1720e55_7957d3fc4c" tabindex="-1" value></div>
    <div class="clear"><input type="submit" value="Subscribe! üóû" name="subscribe" id="mc-embedded-subscribe" class="button"></div>
    </div>
</form>
</div>
<!-- /Mailchimp -->
    </div>


    <div id="acknowledgement">
      <img src="./images/atsi.webp" />
      <p> Braneshop is located on the traditional lands of the people of the
      Kulin nation. We acknowledge that sovereignty was never ceded and pay
      our respects to elders past, present and emerging.
      </p>
    </div>

    <div id="small-links">
      <a href="./">Home</a> &mdash;
      <a href="./contact.html">Contact</a> &mdash;
      <a href="./team.html">Team</a> &mdash;
      <a href="./faq.html">FAQs</a> &mdash;
      <a href="./blog.html">Blog</a> &mdash;
      <a href="./privacy.html">Privacy Policy</a> &mdash;
      <a href="./quickstart.html">Deep Learning Quick-Start</a>
      <a href="./thesetestimonialsdontexist.html">These testimonials don't exist ...</a>
    </div>
  </div>


<script type="text/javascript">
window.onload = function() {
  const prism = document.getElementById("braneshop-fixed")
  var h = 80;

  function setFrame(frame) {
    var f = frame % 120;
    prism.style["background-position"] = "0 " + "-" + (f*h) + "pt";
  }

  document.addEventListener('scroll', function(x) {
  	setFrame(Math.floor(window.scrollY/30))
  }, false)
}
</script>

</body>
</html>
